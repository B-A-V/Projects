{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "### Инструкция по выполнению проекта\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import torch\n",
    "import transformers\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgbm\n",
    "import catboost as catboost\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем датасет и посмотрим на него."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 колонки и 159571 строчка. Text содержит текст комментария, а toxic содержит целевой признак - токсичный комментарий или нет. Сначала проверим на базовые ошибки, а потом потребуется лемматизация и подготовка к обучению моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубликатов нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим данные к обучению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим корпус данных для обучения модели из обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = list(df['text'])\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем формулу очистки текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим от ненужных символов наш корпус."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation Why the edits made under my username Hardcore Metallica Fan were reverted  They weren t vandalisms  just closure on some GAs after I voted at New York Dolls FAC  And please don t remove the template from the talk page since I m retired now             \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpus[i] = clear_text(corpus[i])\n",
    "    \n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем твиты на слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Explanation', 'Why', 'the', 'edits', 'made', 'under', 'my', 'username', 'Hardcore', 'Metallica', 'Fan', 'were', 'reverted', 'They', 'weren', 't', 'vandalisms', 'just', 'closure', 'on', 'some', 'GAs', 'after', 'I', 'voted', 'at', 'New', 'York', 'Dolls', 'FAC', 'And', 'please', 'don', 't', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'I', 'm', 'retired', 'now']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpus[i] = nltk.word_tokenize(corpus[i])\n",
    "    \n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем формулу лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemm_list = lemmatizer.lemmatize(text)\n",
    "    return lemm_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как лемматизатор воспринимает только по одному слову, то напишем цикл для него."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Explanation', 'Why', 'the', 'edits', 'made', 'under', 'my', 'username', 'Hardcore', 'Metallica', 'Fan', 'were', 'reverted', 'They', 'weren', 't', 'vandalism', 'just', 'closure', 'on', 'some', 'GAs', 'after', 'I', 'voted', 'at', 'New', 'York', 'Dolls', 'FAC', 'And', 'please', 'don', 't', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'I', 'm', 'retired', 'now']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(corpus)):\n",
    "    for n in range(len(corpus[i])):\n",
    "        corpus[i][n] = lemmatize(corpus[i][n])        \n",
    "\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим твиты обратно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation Why the edits made under my username Hardcore Metallica Fan were reverted They weren t vandalism just closure on some GAs after I voted at New York Dolls FAC And please don t remove the template from the talk page since I m retired now\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpus[i] = \" \".join(corpus[i])\n",
    "    \n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем список английских стоп-слов и добавим счетчик, который преобразует корпус текстов в мешок слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords') \n",
    "stop_words = set(stopwords.words('english')) \n",
    "count_vect = CountVectorizer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Передадим счётчику корпус текстов. Для этого вызовем fit_transform(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = count_vect.fit_transform(corpus) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на размер мешка без учета стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер мешка без учёта стоп-слов: (159571, 164412)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер мешка без учёта стоп-слов:\", bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь передадим счетику список стоп-слов и получим новый мешок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words=stop_words)\n",
    "bow = count_vect.fit_transform(corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер мешка с учётом стоп-слов: (159571, 164267)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер мешка с учётом стоп-слов:\", bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь рассчитаем TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words) \n",
    "tf_idf = count_tf_idf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (159571, 164267)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер матрицы:\", tf_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на выборки - обучающую, валдицаионную и тестовую - и проверим все ли верно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, features_test, target, target_test = train_test_split(tf_idf, \n",
    "                                    df.toxic, test_size = 0.2, train_size = 0.8)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, \n",
    "                                    target, test_size = 0.25, train_size = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31915x164267 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 877422 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<95742x164267 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2600809 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31914x164267 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 865670 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102734    0\n",
       "98715     1\n",
       "87972     0\n",
       "120570    1\n",
       "131827    0\n",
       "         ..\n",
       "118341    0\n",
       "23051     0\n",
       "69805     0\n",
       "154423    0\n",
       "74794     0\n",
       "Name: toxic, Length: 31915, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51186     0\n",
       "140687    0\n",
       "121290    0\n",
       "115830    0\n",
       "46195     0\n",
       "         ..\n",
       "4247      0\n",
       "65338     0\n",
       "52207     0\n",
       "126801    0\n",
       "15886     0\n",
       "Name: toxic, Length: 95742, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157495    0\n",
       "20796     0\n",
       "90357     0\n",
       "153253    0\n",
       "26535     1\n",
       "         ..\n",
       "71124     1\n",
       "138450    0\n",
       "114563    0\n",
       "49673     1\n",
       "149058    0\n",
       "Name: toxic, Length: 31914, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с модели логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем подобрать оптимальные параметры с помощью gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = make_scorer(f1_score , average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 9, 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametrs_lr = { 'C': range (1, 10, 1),\n",
    "              'class_weight': ['balanced'],\n",
    "              }\n",
    "\n",
    "grid = GridSearchCV(model, parametrs_lr, scoring = 'f1', cv=5)\n",
    "grid.fit(features_train, target_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=9, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=12345, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, C=9, class_weight='balanced')\n",
    "model.fit(features_train, target_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем предсказания и получим accuracy_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1_score 0.7646885149099498\n",
      "Logistic Regression accuracy_score 0.9500548331505562\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(features_test)\n",
    "print('Logistic Regression F1_score', f1_score(target_test, pred))\n",
    "print('Logistic Regression accuracy_score', accuracy_score(target_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score 0.7646885149099498\n"
     ]
    }
   ],
   "source": [
    "print('F1_score', f1_score(target_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нижний порог в 0.75 преодолен, качество модели нас устраивает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем к градиентному бустингу. Попробуем LGB классификатор и подберем оптимальные параметры с помощью Gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.9, 'n_estimators': 1}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb = lgbm.LGBMClassifier()\n",
    "\n",
    "params_lgb = {'n_estimators': range (1, 10, 2),\n",
    "              'learning_rate': [0.1, 0.9],\n",
    "             }\n",
    " \n",
    "grid_lgb = GridSearchCV(lgb, params_lgb, scoring = 'f1', cv=5)\n",
    "\n",
    "grid_lgb.fit(features_train, target_train)\n",
    "\n",
    "grid_lgb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.9, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=2, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb = lgbm.LGBMClassifier(n_estimators = 2, learning_rate = 0.9)\n",
    "\n",
    "lgb.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB F1_score 0.5095119933829612\n",
      "LGB accuracy_score 0.9256775810747297\n"
     ]
    }
   ],
   "source": [
    "predictions_lgb = lgb.predict(features_test)\n",
    "print('LGB F1_score', f1_score(target_test, predictions_lgb))\n",
    "print('LGB accuracy_score', accuracy_score(target_test, predictions_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5919562\ttotal: 3.76s\tremaining: 0us\n",
      "0:\tlearn: 0.5940476\ttotal: 3.95s\tremaining: 0us\n",
      "0:\tlearn: 0.5943452\ttotal: 3.95s\tremaining: 0us\n",
      "0:\tlearn: 0.5956625\ttotal: 4.01s\tremaining: 0us\n",
      "0:\tlearn: 0.5937408\ttotal: 4.07s\tremaining: 0us\n",
      "0:\tlearn: 0.5919562\ttotal: 3.97s\tremaining: 19.8s\n",
      "1:\tlearn: 0.5139538\ttotal: 7.26s\tremaining: 14.5s\n",
      "2:\tlearn: 0.4551488\ttotal: 10.6s\tremaining: 10.6s\n",
      "3:\tlearn: 0.4088155\ttotal: 13.8s\tremaining: 6.88s\n",
      "4:\tlearn: 0.3725016\ttotal: 17.1s\tremaining: 3.41s\n",
      "5:\tlearn: 0.3442528\ttotal: 20.4s\tremaining: 0us\n",
      "0:\tlearn: 0.5940476\ttotal: 4.01s\tremaining: 20.1s\n",
      "1:\tlearn: 0.5145838\ttotal: 7.31s\tremaining: 14.6s\n",
      "2:\tlearn: 0.4546235\ttotal: 10.6s\tremaining: 10.6s\n",
      "3:\tlearn: 0.4076458\ttotal: 13.9s\tremaining: 6.96s\n",
      "4:\tlearn: 0.3716072\ttotal: 17.3s\tremaining: 3.46s\n",
      "5:\tlearn: 0.3424688\ttotal: 20.6s\tremaining: 0us\n",
      "0:\tlearn: 0.5943452\ttotal: 3.95s\tremaining: 19.7s\n",
      "1:\tlearn: 0.5191434\ttotal: 7.24s\tremaining: 14.5s\n",
      "2:\tlearn: 0.4582333\ttotal: 10.5s\tremaining: 10.5s\n",
      "3:\tlearn: 0.4120013\ttotal: 13.8s\tremaining: 6.92s\n",
      "4:\tlearn: 0.3742388\ttotal: 17.1s\tremaining: 3.43s\n",
      "5:\tlearn: 0.3435534\ttotal: 20.5s\tremaining: 0us\n",
      "0:\tlearn: 0.5956625\ttotal: 4.01s\tremaining: 20.1s\n",
      "1:\tlearn: 0.5178830\ttotal: 7.31s\tremaining: 14.6s\n",
      "2:\tlearn: 0.4548958\ttotal: 10.7s\tremaining: 10.7s\n",
      "3:\tlearn: 0.4083469\ttotal: 14s\tremaining: 7.01s\n",
      "4:\tlearn: 0.3714242\ttotal: 17.3s\tremaining: 3.46s\n",
      "5:\tlearn: 0.3429485\ttotal: 20.7s\tremaining: 0us\n",
      "0:\tlearn: 0.5937408\ttotal: 4.06s\tremaining: 20.3s\n",
      "1:\tlearn: 0.5196526\ttotal: 7.45s\tremaining: 14.9s\n",
      "2:\tlearn: 0.4575794\ttotal: 10.8s\tremaining: 10.8s\n",
      "3:\tlearn: 0.4087548\ttotal: 14.1s\tremaining: 7.03s\n",
      "4:\tlearn: 0.3745703\ttotal: 17.4s\tremaining: 3.47s\n",
      "5:\tlearn: 0.3475334\ttotal: 20.7s\tremaining: 0us\n",
      "0:\tlearn: 0.2627259\ttotal: 4.07s\tremaining: 0us\n",
      "0:\tlearn: 0.2696253\ttotal: 4.16s\tremaining: 0us\n",
      "0:\tlearn: 0.2717049\ttotal: 4.04s\tremaining: 0us\n",
      "0:\tlearn: 0.2777788\ttotal: 4.08s\tremaining: 0us\n",
      "0:\tlearn: 0.2696515\ttotal: 4.01s\tremaining: 0us\n",
      "0:\tlearn: 0.2627259\ttotal: 4.24s\tremaining: 21.2s\n",
      "1:\tlearn: 0.2300999\ttotal: 7.55s\tremaining: 15.1s\n",
      "2:\tlearn: 0.2136307\ttotal: 10.9s\tremaining: 10.9s\n",
      "3:\tlearn: 0.2013885\ttotal: 14.3s\tremaining: 7.17s\n",
      "4:\tlearn: 0.1937227\ttotal: 17.8s\tremaining: 3.57s\n",
      "5:\tlearn: 0.1870203\ttotal: 21.3s\tremaining: 0us\n",
      "0:\tlearn: 0.2696253\ttotal: 4.13s\tremaining: 20.6s\n",
      "0:\tlearn: 0.2777788\ttotal: 3.98s\tremaining: 19.9s\n",
      "1:\tlearn: 0.2373373\ttotal: 7.37s\tremaining: 14.7s\n",
      "2:\tlearn: 0.2166435\ttotal: 10.8s\tremaining: 10.8s\n",
      "3:\tlearn: 0.2043402\ttotal: 14s\tremaining: 6.99s\n",
      "4:\tlearn: 0.1965330\ttotal: 17.3s\tremaining: 3.45s\n",
      "5:\tlearn: 0.1901267\ttotal: 20.6s\tremaining: 0us\n",
      "0:\tlearn: 0.2696515\ttotal: 3.96s\tremaining: 19.8s\n",
      "1:\tlearn: 0.2358116\ttotal: 7.26s\tremaining: 14.5s\n",
      "2:\tlearn: 0.2193700\ttotal: 10.5s\tremaining: 10.5s\n",
      "3:\tlearn: 0.2043894\ttotal: 13.9s\tremaining: 6.93s\n",
      "4:\tlearn: 0.1953261\ttotal: 17.2s\tremaining: 3.43s\n",
      "5:\tlearn: 0.1897900\ttotal: 20.5s\tremaining: 0us\n",
      "0:\tlearn: 0.2646743\ttotal: 4.77s\tremaining: 23.8s\n",
      "1:\tlearn: 0.2317042\ttotal: 8.68s\tremaining: 17.4s\n",
      "2:\tlearn: 0.2123041\ttotal: 12.8s\tremaining: 12.8s\n",
      "3:\tlearn: 0.2008536\ttotal: 16.7s\tremaining: 8.33s\n",
      "4:\tlearn: 0.1939234\ttotal: 20.5s\tremaining: 4.09s\n",
      "5:\tlearn: 0.1886113\ttotal: 24.5s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.9, 'n_estimators': 6}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctb = catboost.CatBoostClassifier()\n",
    "\n",
    "params_ctb = {'n_estimators': range (1, 10, 5),\n",
    "              'learning_rate': [0.1, 0.9],\n",
    "             }\n",
    " \n",
    "grid_ctb = GridSearchCV(ctb, params_ctb, scoring = 'f1', cv=5)\n",
    "\n",
    "grid_ctb.fit(features_train, target_train)\n",
    "\n",
    "grid_ctb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2646743\ttotal: 4.74s\tremaining: 23.7s\n",
      "1:\tlearn: 0.2317042\ttotal: 8.73s\tremaining: 17.5s\n",
      "2:\tlearn: 0.2123041\ttotal: 12.8s\tremaining: 12.8s\n",
      "3:\tlearn: 0.2008536\ttotal: 16.8s\tremaining: 8.42s\n",
      "4:\tlearn: 0.1939234\ttotal: 20.8s\tremaining: 4.17s\n",
      "5:\tlearn: 0.1886113\ttotal: 24.7s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f1e1a4b7590>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctb = catboost.CatBoostClassifier(n_estimators = 6, learning_rate = 0.9)\n",
    "\n",
    "ctb.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost F1_score 0.6565349544072948\n",
      "CatBoost accuracy_score 0.9433495221682594\n"
     ]
    }
   ],
   "source": [
    "predictions_ctb = ctb.predict(features_test)\n",
    "print('CatBoost F1_score', f1_score(target_test, predictions_ctb))\n",
    "print('CatBoost accuracy_score', accuracy_score(target_test, predictions_ctb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целью нашей работы было построить модель, наиболее качественно определяющую токсичные твиты. После обработки всех сообщений в датасете и приведения их к требуемому формату, учитывающему форму слова и их вес в предложении, мы попробовали три разные модели. Простая логистическая регрессия с подбором параметра \"С\" и сбалансированным весом классов показала уровень метрики F1 выше требуемых 0.75. \n",
    "Далее мы попытались воспользоваться бустингами классификации LGBM и CatBoost, но они не дали требуемого показателя метрики F1. Поэтому наш выбор - логистическая регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
